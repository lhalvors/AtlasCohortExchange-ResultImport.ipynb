{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas Cohort Exchange - Cohort Definition Export\n",
    "This notebook is meant for exporting the cohort definition from the central Atlas site for subsequent import into external Atlas sites.\n",
    "\n",
    "This is step 1 in the overall Atlas Cohort Exchange process:\n",
    "1. Export cohort definition as a JSON file - this step (_see Atlas Cohort Exchange - Admin.docx_)\n",
    "2. Create the same cohort definition at remote Atlas site using the **AtlasCohortExchange R** package, then create inclusion report (_see Atlas Cohort Exchange - User Guide.docx_)\n",
    "3. Export cohort inclusion report results to JSON file using the **AtlasCohortExchange R** package (_see Atlas Cohort Exchange - User Guide.docx_)\n",
    "4. Import cohort inclusion report results into central Atlas instance using the **AtlasCohortExchange-ResultImport** Jupyter notebook (_see Atlas Cohort Exchange - Admin.docx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters - check/modify before running rest of notebook\n",
    "These are the parameters to be used when connecting to the central Atlas database to export the cohort definition.\n",
    "\n",
    "###### Database parameters\n",
    "The parameters needed for connecting to the relevant database and (webapi) schema of the central Atlas site.\n",
    "\n",
    "###### Cohort definition ID\n",
    "The cohort_definition_id of the central Atlas instance for the cohort definition to export and share with external Atlas site(s).\n",
    "\n",
    "###### Path to the JSON file & file name for JSON file\n",
    "The directory path to the JSON file in which the cohort definition should be saved, and the file name to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Database parameters ##### \n",
    "dbDbms = 'postgresql' #  ONLY POSTGRESQL SUPPORTED CURRENTLY\n",
    "dbAddress = '34.251.82.109'\n",
    "dbDatabase = 'omop1'\n",
    "dbSchema = 'webapi'\n",
    "dbUser = 'atlasuser'\n",
    "dbPassword='ec2-psql'\n",
    "\n",
    "# ##### Cohort definition ID ##### \n",
    "cohortId=146\n",
    "\n",
    "# ##### Path to and name of the JSON file: ##### \n",
    "# #####   jsonFileDirecory: the path where the JSON file should be saved\n",
    "# #####   jsonFileName: defaults to 'cohort_xxx_def.json', where xxx is the cohort definition id ##### \n",
    "jsonFileDirecory = 'C:/dwn/'\n",
    "jsonFileName = 'cohort_' + str(cohortId) + '_def.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code - export the cohort definition\n",
    "Once the parameters above have been checked/modified, please run the remainder of the notebook cells to export the cohort definition to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pymssql\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection string - ONLY POSTGRESQL SUPPORTED CURRENTLY\n",
    "if dbDbms == 'postgresql':\n",
    "    dbConnectionString = 'postgresql+psycopg2://' + dbUser + ':' + dbPassword + '@' + dbAddress + '/' + dbDatabase\n",
    "else:\n",
    "    dbConnectionString = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify database\n",
    "engine = create_engine(dbConnectionString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cohort_definition\n",
    "sql = 'select * from ' + dbSchema + '.cohort_definition where id=' + str(cohortId)\n",
    "cd=pd.read_sql(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cohort_definition_details\n",
    "sql = 'select * from ' + dbSchema + '.cohort_definition_details where id=' + str(cohortId)\n",
    "cdd=pd.read_sql(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two JSON outputs\n",
    "out_str = '[{\"cohort_definition\": ' + cd.to_json(date_format='iso') + '},'\n",
    "out_str += '{\"cohort_definition_details\": ' + cdd.to_json(date_format='iso') + '}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the JSON file\n",
    "jsonFilePath = jsonFileDirecory + jsonFileName\n",
    "with open(jsonFilePath, 'w') as data_file:    \n",
    "    data_file.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
